{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScenarioType(str, Enum):\n",
    "    \"\"\"Type of collection call scenario.\"\"\"\n",
    "    PTP = \"PTP\"\n",
    "    REFUSE_TO_PAY = \"REFUSE_TO_PAY\"\n",
    "    TPC = \"TPC\"\n",
    "    UNKNOWN = \"UNKNOWN\"\n",
    "\n",
    "class Amount(BaseModel):\n",
    "    \"\"\"Amount mentioned in the conversation.\"\"\"\n",
    "    value: float = Field(..., description=\"The monetary value\")\n",
    "    currency: str = Field(default=\"IDR\", description=\"Currency of the amount\")\n",
    "    type: str = Field(..., description=\"Type of amount (e.g., installment, penalty, total)\")\n",
    "\n",
    "class BasicCallInfo(BaseModel):\n",
    "    \"\"\"Basic information extracted from a collection call.\"\"\"\n",
    "    agent_name: Optional[str] = Field(\n",
    "        default=None, \n",
    "        description=\"Name of the collection agent\"\n",
    "    )\n",
    "    customer_name: Optional[str] = Field(\n",
    "        default=None, \n",
    "        description=\"Name of the customer being contacted\"\n",
    "    )\n",
    "    scenario_type: ScenarioType = Field(\n",
    "        default=ScenarioType.UNKNOWN,\n",
    "        description=\"Type of collection scenario identified\"\n",
    "    )\n",
    "    call_duration: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Duration of the call in timestamp format\"\n",
    "    )\n",
    "    amounts_mentioned: List[Amount] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of monetary amounts mentioned in the call\"\n",
    "    )\n",
    "    payment_date_mentioned: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Any payment date mentioned in the conversation\"\n",
    "    )\n",
    "\n",
    "class PTPDetails(BaseModel):\n",
    "    \"\"\"Additional details specific to PTP (Promise to Pay) scenario.\"\"\"\n",
    "    promised_date: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Date customer promised to pay\"\n",
    "    )\n",
    "    promised_amount: Optional[Amount] = Field(\n",
    "        default=None,\n",
    "        description=\"Amount customer promised to pay\"\n",
    "    )\n",
    "    negotiation_attempts: Optional[int] = Field(\n",
    "        default=None,\n",
    "        description=\"Number of times agent attempted to negotiate payment\"\n",
    "    )\n",
    "\n",
    "class RefuseDetails(BaseModel):\n",
    "    \"\"\"Additional details specific to Refuse to Pay scenario.\"\"\"\n",
    "    reason: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Main reason given for refusing payment\"\n",
    "    )\n",
    "    customer_situation: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Description of customer's stated situation or obstacles\"\n",
    "    )\n",
    "\n",
    "class TPCDetails(BaseModel):\n",
    "    \"\"\"Additional details specific to Third Party Contact scenario.\"\"\"\n",
    "    relationship_to_customer: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Relationship of the contacted person to the customer\"\n",
    "    )\n",
    "    message_delivered: Optional[bool] = Field(\n",
    "        default=None,\n",
    "        description=\"Whether a message was successfully delivered\"\n",
    "    )\n",
    "\n",
    "class CallData(BaseModel):\n",
    "    \"\"\"Complete extraction of collection call data.\"\"\"\n",
    "    basic_info: BasicCallInfo\n",
    "    ptp_details: Optional[PTPDetails] = Field(\n",
    "        default=None,\n",
    "        description=\"Details specific to PTP scenario, if applicable\"\n",
    "    )\n",
    "    refuse_details: Optional[RefuseDetails] = Field(\n",
    "        default=None,\n",
    "        description=\"Details specific to Refuse to Pay scenario, if applicable\"\n",
    "    )\n",
    "    tpc_details: Optional[TPCDetails] = Field(\n",
    "        default=None,\n",
    "        description=\"Details specific to Third Party Contact scenario, if applicable\"\n",
    "    )\n",
    "    call_summary: Optional[str] = Field(\n",
    "        default=None,\n",
    "        description=\"Brief summary of the key points from the call\"\n",
    "    )\n",
    "\n",
    "# Prompt template for the extraction\n",
    "prompt_template = \"\"\"\n",
    "You are an expert collection call analyzer. Your task is to extract relevant information from collection call transcripts in Indonesian language.\n",
    "\n",
    "Key things to look for:\n",
    "1. Identify the type of call scenario (PTP, Refuse to Pay, or TPC)\n",
    "2. Extract basic call information\n",
    "3. Extract scenario-specific details\n",
    "4. Create a brief summary\n",
    "\n",
    "Remember:\n",
    "- Only extract information that is explicitly present in the transcript\n",
    "- Return null for any information that cannot be confidently extracted\n",
    "- Pay attention to Indonesian language patterns and context\n",
    "- Look for monetary amounts, dates, and key phrases that indicate the scenario type\n",
    "\n",
    "Transcript to analyze:\n",
    "{text}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\")  # or your preferred model\n",
    "structured_llm = llm.with_structured_output(schema=CallData)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt_template),\n",
    "    (\"human\", \"{text}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_transcript(transcript_text):\n",
    "    prompt_value = prompt.invoke({\"text\": transcript_text})\n",
    "    return structured_llm.invoke(prompt_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "[00:00.000 --> 00:25.400]  Halo selamat pagi Rp. 4.000, Bapak. Untuk angkusan BV-nya, apakah sudah bisa dibayarkannya hari ini, Bapak Jalaluddin?\n",
    "[00:29.440 --> 00:30.100]  Halo, Pak?\n",
    "[00:30.120 --> 00:31.140]  Ini dari mana ini?\n",
    "[00:31.560 --> 00:36.340]  Dari mana? Dari BV Finance, Pak. Ini untuk angkusan Mitsubishi Cloud-nya, Pak, yang warna kuning.\n",
    "[00:36.900 --> 00:40.080]  Untuk angkusan BV-nya, apakah sudah bisa dibayarkannya hari ini, Bapak Jalaluddin?\n",
    "[00:48.160 --> 00:53.800]  Tapi kalau nggak ada kopnya B mana-mana namanya namanya gimana maksudnya ini dengan Bapak jalurin kan Pak\n",
    "[00:53.800 --> 01:07.380]  saya kena bilang saya novel dari BV Finance saya novel dari BV Finance Pak Angson BFI nya Bapak sudah Oh setiap yang nelfon ganti-ganti kenapa?\n",
    "[01:07.640 --> 01:09.420]  Iya ini tau-tau telfonnya by system Pak\n",
    "[01:09.420 --> 01:12.440]  Ini Angson BFI nya sudah ketambahannya 1 hari\n",
    "[01:12.440 --> 01:14.220]  Dengan nominal yang harus dibayarkan disini\n",
    "[01:14.220 --> 01:17.060]  Rp. 6.364.000\n",
    "[01:17.060 --> 01:20.540]  Angson BFI nya Pak apakah sudah bisa dibayar hari ini?\n",
    "[01:21.000 --> 01:21.920]  Bapak Jalaludin\n",
    "[01:21.920 --> 01:25.880]  Saya belum bisa masjidkan\n",
    "[01:25.880 --> 01:27.380]  kenapa? kendalanya apa?\n",
    "[01:28.280 --> 01:30.220]  hujan, gak bisa panen\n",
    "[01:30.220 --> 01:32.060]  untuk kejadian ini kan juga bukan\n",
    "[01:32.060 --> 01:33.700]  kejadian yang pertama Pak, dan Bapak juga bisa\n",
    "[01:33.700 --> 01:35.620]  antisipasi juga sebelumnya, karena disini\n",
    "[01:35.620 --> 01:37.840]  untuk tanggal jatuh tembani Bapak sendiri juga disini\n",
    "[01:37.840 --> 01:46.780]  tidak akan menabur Bapak setiap bulannya karena jika pembayarannya Bapak di sini bagus, saat pengajuannya kembali juga nantinya akan dipermudah juga. Jadi sekarang bisa dibayarkan dua kali kan di tanggal berapa?\n",
    "[01:46.820 --> 01:47.420]  Iya, kamu bicara banyak.\n",
    "[01:47.900 --> 01:48.680]  Di tanggal berapa?\n",
    "[01:48.780 --> 01:49.340]  Saya tidak tahu.\n",
    "[01:49.660 --> 01:51.000]  Di tanggal berapa bisa dibayar?\n",
    "[01:51.020 --> 01:52.800]  Kalau menunggu hujan, travel alam.\n",
    "[01:54.400 --> End Recording]  Ini sudah ketempatan satu hari Pak, jika pembayarannya selalu tidak tepat waktu, maka\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = analyze_transcript(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"basic_info\":{\"agent_name\":\"Novel\",\"customer_name\":\"Bapak Jalaluddin\",\"scenario_type\":\"REFUSE_TO_PAY\",\"call_duration\":\"[00:00.000 --> 01:54.400]\",\"amounts_mentioned\":[{\"value\":6364000.0,\"currency\":\"IDR\",\"type\":\"installment\"}],\"payment_date_mentioned\":null},\"ptp_details\":null,\"refuse_details\":{\"reason\":\"hujan, gak bisa panen\",\"customer_situation\":\"Bapak Jalaluddin tidak bisa membayar karena cuaca hujan yang menghambat panen.\"},\"tpc_details\":null,\"call_summary\":\"Agent Novel from BV Finance contacted Bapak Jalaluddin regarding an overdue installment payment of IDR 6,364,000. Bapak Jalaluddin refused to pay, citing rain that prevented harvesting as the reason for his inability to pay. The agent attempted to negotiate a payment date but was unsuccessful.\"}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.model_dump_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, List, Dict\n",
    "from pydantic import BaseModel, Field\n",
    "from enum import Enum\n",
    "\n",
    "# [Previous Enum and Model definitions remain the same...]\n",
    "# Basic Enums and Types through Complete QA Score Model stay unchanged\n",
    "\n",
    "# Updated Scoring Prompt Template with proper variable handling\n",
    "SCORING_ANALYSIS_PROMPT = \"\"\"You are an expert QA analyst for collection call centers, specializing in evaluating agent performance based on strict QA criteria. Your task is to analyze a call transcript and extract detailed scoring information.\n",
    "\n",
    "Context: The call has already been classified as {scenario_type}. You will evaluate the call based on the appropriate QA form criteria for this scenario type.\n",
    "\n",
    "Required Output Format:\n",
    "The output should be a JSON object matching the following structure example:\n",
    "{{\n",
    "    \"scenario_type\": \"{scenario_type}\",\n",
    "    \"opening_score\": {{\n",
    "        \"greeting_score\": \"0|0.5|1\",\n",
    "        \"greeting_evidence\": \"exact quote from transcript\",\n",
    "        \"customer_name_verification\": \"COMPLIANT|NON_COMPLIANT|NOT_APPLICABLE\",\n",
    "        \"customer_verification_evidence\": \"exact quote or null\",\n",
    "        \"mandatory_info_disclosed\": [\"list of disclosed items\"]\n",
    "    }},\n",
    "    \"communication_score\": {{\n",
    "        \"voice_tone_score\": \"0|0.5|1\",\n",
    "        \"voice_tone_evidence\": \"evidence or null\",\n",
    "        \"speaking_pace_score\": \"0|0.5|1\",\n",
    "        \"speaking_pace_evidence\": \"evidence or null\",\n",
    "        \"language_etiquette_score\": \"0|0.5|1\",\n",
    "        \"language_evidence\": [\"examples\"]\n",
    "    }},\n",
    "    \"negotiation_score\": {{\n",
    "        \"negotiation_attempts\": number,\n",
    "        \"solutions_offered\": [\"list of solutions\"],\n",
    "        \"payment_commitment_obtained\": boolean,\n",
    "        \"negotiation_evidence\": [\"key phrases\"]\n",
    "    }},\n",
    "    \"knockout_violations\": {{\n",
    "        \"unauthorized_disclosure\": boolean,\n",
    "        \"disclosure_evidence\": \"evidence or null\",\n",
    "        \"ptp_cheating\": boolean,\n",
    "        \"ptp_cheating_evidence\": \"evidence or null\",\n",
    "        \"other_violations\": [\"list of violations\"]\n",
    "    }},\n",
    "    \"total_score\": number between 0-1,\n",
    "    \"score_breakdown\": {{\n",
    "        \"opening\": number,\n",
    "        \"communication\": number,\n",
    "        \"negotiation\": number\n",
    "    }},\n",
    "    \"improvement_areas\": [\"list of areas\"],\n",
    "    \"evidence_highlights\": [\"list of key evidence\"]\n",
    "}}\n",
    "\n",
    "Evaluation Guidelines:\n",
    "\n",
    "1. Opening Section (6% weight):\n",
    "- Listen for proper greeting, agent name, and company name\n",
    "- Verify correct customer name usage\n",
    "- Check for mandatory information disclosure\n",
    "- Score: 0 (non-compliant), 0.5 (standard), 1 (strong)\n",
    "\n",
    "2. Communication Skills (25% total weight):\n",
    "- Voice tone (6%): Energy, professionalism, confidence\n",
    "- Speaking pace (6%): Clear articulation, appropriate speed\n",
    "- Language etiquette (13%): Politeness, appropriate phrases\n",
    "- Score each component: 0 (poor), 0.5 (acceptable), 1 (excellent)\n",
    "\n",
    "3. Negotiation Skills (40% total weight, for PTP/RTP):\n",
    "- Track negotiation attempts\n",
    "- Document solutions offered\n",
    "- Verify payment commitments\n",
    "- Evaluate effectiveness: 0 (ineffective), 0.5 (moderate), 1 (highly effective)\n",
    "\n",
    "4. Knockout Criteria (Immediate Fail):\n",
    "- Information disclosure to unauthorized parties\n",
    "- PTP cheating\n",
    "- Policy violations\n",
    "- Document any violations with specific evidence\n",
    "\n",
    "Important:\n",
    "- Provide specific evidence from the transcript for each score\n",
    "- Score breakdown must add up to total score\n",
    "- All mandatory fields must be included in the output\n",
    "- Use exact quotes when providing evidence\n",
    "\n",
    "Call Transcript to analyze:\n",
    "{text}\n",
    "\n",
    "Analyze the transcript and provide a complete evaluation following the exact structure shown above.\"\"\"\n",
    "\n",
    "def create_scenario_specific_prompt(scenario_type: str, base_prompt: str) -> str:\n",
    "    \"\"\"Customize scoring prompt based on scenario type\"\"\"\n",
    "    \n",
    "    scenario_additions = {\n",
    "        \"PTP\": \"\"\"\n",
    "Additional PTP Criteria:\n",
    "- Focus on commitment clarity\n",
    "- Verify payment amount and date\n",
    "- Check for proper confirmation\n",
    "- Evaluate follow-up scheduling\"\"\",\n",
    "        \n",
    "        \"REFUSE_TO_PAY\": \"\"\"\n",
    "Additional RTP Criteria:\n",
    "- Evaluate reason documentation\n",
    "- Check solution exploration\n",
    "- Assess escalation handling\n",
    "- Monitor professional persistence\"\"\",\n",
    "        \n",
    "        \"TPC\": \"\"\"\n",
    "Additional TPC Criteria:\n",
    "- Verify relationship confirmation\n",
    "- Check information protection\n",
    "- Evaluate message clarity\n",
    "- Assess contact information gathering\"\"\"\n",
    "    }\n",
    "    \n",
    "    return base_prompt + scenario_additions.get(scenario_type, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAScoringAnalyzer:\n",
    "    \"\"\"Handles QA scoring analysis using LangChain\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"gpt-3.5-turbo\", temperature: float = 0):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        self.structured_llm = self.llm.with_structured_output(QAScore)\n",
    "        \n",
    "    def analyze_call(self, \n",
    "                    transcript: str, \n",
    "                    scenario_type: ScenarioType,\n",
    "                    custom_prompt: Optional[str] = None) -> QAScore:\n",
    "        \"\"\"Analyze a call transcript and return structured QA scoring\"\"\"\n",
    "        \n",
    "        # Create scenario-specific prompt\n",
    "        base_prompt = custom_prompt or SCORING_ANALYSIS_PROMPT\n",
    "        final_prompt = create_scenario_specific_prompt(scenario_type, base_prompt)\n",
    "        \n",
    "        # Create prompt template\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", final_prompt),\n",
    "            (\"human\", \"{text}\")\n",
    "        ])\n",
    "        \n",
    "        # Generate prompt values\n",
    "        prompt_value = prompt.invoke({\n",
    "            \"text\": transcript,\n",
    "            \"scenario_type\": scenario_type\n",
    "        })\n",
    "        \n",
    "        # Get structured output\n",
    "        try:\n",
    "            result = self.structured_llm.invoke(prompt_value)\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Error during QA scoring analysis: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Score: 0.625\n",
      "Score Breakdown: {'opening': 0.0, 'communication': 0.0, 'negotiation': 0.0}\n",
      "Improvement Areas: ['Improve speaking pace for better clarity.', 'Enhance negotiation skills to obtain payment commitment.']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import Optional\n",
    "\n",
    "class QAScoringAnalyzer:\n",
    "    \"\"\"Handles QA scoring analysis using LangChain\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"gpt-3.5-turbo\", temperature: float = 0):\n",
    "        self.llm = ChatOpenAI(\n",
    "            model=model_name,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        self.structured_llm = self.llm.with_structured_output(QAScore)\n",
    "        \n",
    "    def analyze_call(self, \n",
    "                    transcript: str, \n",
    "                    scenario_type: ScenarioType) -> QAScore:\n",
    "        \"\"\"Analyze a call transcript and return structured QA scoring\"\"\"\n",
    "        \n",
    "        # Create prompt template with proper escaping\n",
    "        prompt = ChatPromptTemplate.from_template(SCORING_ANALYSIS_PROMPT)\n",
    "        \n",
    "        try:\n",
    "            # Generate prompt values\n",
    "            prompt_value = prompt.invoke({\n",
    "                \"text\": transcript,\n",
    "                \"scenario_type\": scenario_type.value\n",
    "            })\n",
    "            \n",
    "            # Get structured output\n",
    "            result = self.structured_llm.invoke(prompt_value)\n",
    "            \n",
    "            # Validate score_breakdown\n",
    "            if not result.score_breakdown:\n",
    "                result.score_breakdown = {\n",
    "                    \"opening\": 0.0,\n",
    "                    \"communication\": 0.0,\n",
    "                    \"negotiation\": 0.0\n",
    "                }\n",
    "                \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Raw error: {str(e)}\")  # For debugging\n",
    "            raise Exception(f\"Error during QA scoring analysis: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "def test_qa_scoring():\n",
    "    # Test transcript\n",
    "    test_transcript = \"\"\"\n",
    "    Agent: Selamat pagi, saya John dari BFI Finance. Bisa bicara dengan Bapak Ahmad?\n",
    "    Customer: Ya, saya sendiri.\n",
    "    Agent: Pak Ahmad, saya menghubungi terkait pembayaran angsuran yang sudah jatuh tempo...\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = QAScoringAnalyzer()\n",
    "    \n",
    "    # Analyze call\n",
    "    try:\n",
    "        qa_score = analyzer.analyze_call(\n",
    "            transcript=text,\n",
    "            scenario_type=ScenarioType.PTP\n",
    "        )\n",
    "        \n",
    "        # Access results\n",
    "        print(f\"Total Score: {qa_score.total_score}\")\n",
    "        print(f\"Score Breakdown: {qa_score.score_breakdown}\")\n",
    "        print(f\"Improvement Areas: {qa_score.improvement_areas}\")\n",
    "        \n",
    "        # Check for knockout violations\n",
    "        if qa_score.knockout_violations.unauthorized_disclosure:\n",
    "            print(\"WARNING: Unauthorized information disclosure detected\")\n",
    "            print(f\"Evidence: {qa_score.knockout_violations.disclosure_evidence}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Analysis failed: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_qa_scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coll-conv-analytics-rkkL712F",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
